{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning - Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azureml\n",
    "\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.core import Workspace, Datastore, Experiment, Model, Run, Environment, ScriptRunConfig\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to workspace\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace:\",ws.name,\"in region\", ws.location)\n",
    "\n",
    "# Connect to compute cluster\n",
    "cluster = ComputeTarget(workspace=ws, name=\"OptimusPrime\")\n",
    "print('Compute cluster:', cluster.name)\n",
    "\n",
    "# Connect to the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Datastore:\",ds.name)\n",
    "\n",
    "# Connect to the experiment\n",
    "experiment = Experiment(workspace=ws, name='Simpsons-PyTorch-Pipeline')\n",
    "print(\"Experiment:\",experiment.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location for the step scripts\n",
    "script_folder = \"./scripts\"\n",
    "\n",
    "# Name of the model\n",
    "model_name = \"Simpsons-PT-Notebook\"\n",
    "\n",
    "# Experiment name\n",
    "experiment_name = \"Simpsons-PT-Pipeline-Notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters make it easy for us to re-run this training pipeline, including for retraining.\n",
    "source_dataset = DataPath(\n",
    "    datastore=ds, \n",
    "    path_on_datastore=\"simpsonslego-v3\")\n",
    "\n",
    "source_dataset_param = (PipelineParameter(name=\"source_dataset\",default_value=source_dataset),\n",
    "                          DataPathComputeBinding())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output location for the pre-proccessed trainings images\n",
    "training_data_location = PipelineData(name=\"simpsons_training_data\", datastore=ds)\n",
    "\n",
    "# Create the pre-process step\n",
    "preProcessDataStep = PythonScriptStep(name=\"Pre-process data\",\n",
    "                            script_name=\"steps/prep.py\",\n",
    "                            compute_target=cluster,\n",
    "                            inputs=[source_dataset_param],\n",
    "                            arguments=['--source_path', source_dataset_param,\n",
    "                                       '--destination_path', training_data_location\n",
    "                                      ],\n",
    "                            outputs=[training_data_location],\n",
    "                            source_directory=script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output location for the produced model\n",
    "model_location = PipelineData(name=\"model\", datastore=ds, output_path_on_compute=\"model\")\n",
    "\n",
    "# Define the training Environment\n",
    "aml_run_config = RunConfiguration()\n",
    "aml_run_config.target = cluster\n",
    "aml_run_config.environment = Environment.get(workspace=ws, name=\"AzureML-PyTorch-1.6-GPU\")\n",
    "\n",
    "script_params = [\n",
    "    '--data-folder', training_data_location,\n",
    "    \"--output-folder\", model_location\n",
    "]\n",
    "\n",
    "\n",
    "trainOnGpuStep = PythonScriptStep(\n",
    "    name = 'Train Model',\n",
    "    script_name = 'steps/train.py',\n",
    "    source_directory = script_folder,\n",
    "    arguments = script_params,\n",
    "    compute_target = cluster,\n",
    "    runconfig = aml_run_config,\n",
    "    inputs=[training_data_location],\n",
    "    outputs=[model_location]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registerModelStep = PythonScriptStep(name=\"Register model in Model Management\",\n",
    "                            script_name=\"steps/register.py\",\n",
    "                            compute_target=cluster,\n",
    "                            inputs=[model_location],\n",
    "                            arguments=['--model_name', model_name,\n",
    "                                       '--model_assets_path', model_location\n",
    "                                      ],\n",
    "                            source_directory=script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpsons_pipeline = Pipeline(workspace=ws, steps=[preProcessDataStep,trainOnGpuStep,registerModelStep])\n",
    "simpsons_pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpipeline = simpsons_pipeline.publish(name=\"Simpsons-PyTorch-Pipeline - Training pipeline (From Notebook)\",)\n",
    "print(\"Pipeline Published ID:\"+mlpipeline.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run = mlpipeline.submit(ws,experiment_name)\n",
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldrun = [r for r in experiment.get_runs() if r.id == '2d50e69d-7615-407f-a27a-fd71371e3085'][0]\n",
    "RunDetails(oldrun).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
