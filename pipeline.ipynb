{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning - Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azureml\n",
    "\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.core import Workspace, Datastore, Experiment, Model, Run\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to workspace\n",
    "ws = Workspace.from_config()\n",
    "print(\"Workspace:\",ws.name,\"in region\", ws.location)\n",
    "\n",
    "# Connect to compute cluster\n",
    "cluster = ComputeTarget(workspace=ws, name=\"OptimusPrime\")\n",
    "print('Compute cluster:', cluster.name)\n",
    "\n",
    "# Connect to the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Datastore:\",ds.name)\n",
    "\n",
    "# Connect to the experiment\n",
    "experiment = Experiment(workspace=ws, name='Simpsons-PyTorch-Pipeline')\n",
    "print(\"Experiment:\",experiment.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters make it easy for us to re-run this training pipeline, including for retraining.\n",
    "source_dataset = DataPath(\n",
    "    datastore=ds, \n",
    "    path_on_datastore=\"simpsonslego-v2\")\n",
    "\n",
    "source_dataset_param = (PipelineParameter(name=\"source_dataset\",default_value=source_dataset),\n",
    "                          DataPathComputeBinding())\n",
    "\n",
    "# Location for the step scripts\n",
    "script_folder = \"./scripts\"\n",
    "\n",
    "# Name of the model\n",
    "model_name = \"Simpsons-PT-Notebook\"\n",
    "\n",
    "# Experiment name\n",
    "experiment_name = \"Simpsons-PT-Pipeline-Notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output location for the pre-proccessed trainings images\n",
    "training_data_location = PipelineData(name=\"simpsons_training_data\", datastore=ds)\n",
    "\n",
    "# Create the pre-process step\n",
    "preProcessDataStep = PythonScriptStep(name=\"Pre-process data\",\n",
    "                            script_name=\"steps/prep.py\",\n",
    "                            compute_target=cluster,\n",
    "                            inputs=[source_dataset_param],\n",
    "                            arguments=['--source_path', source_dataset_param,\n",
    "                                       '--destination_path', training_data_location\n",
    "                                      ],\n",
    "                            outputs=[training_data_location],\n",
    "                            source_directory=script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output location for the produced model\n",
    "model_location = PipelineData(name=\"model\", datastore=ds, output_path_on_compute=\"model\")\n",
    "\n",
    "# Estimator script params\n",
    "estimator_script_params = [\n",
    "    \"--data-folder\", training_data_location,\n",
    "    \"--output-folder\", model_location\n",
    "]\n",
    "\n",
    "# Create the PyTorch Estimator\n",
    "trainEstimator = PyTorch(\n",
    "                     source_directory = script_folder,\n",
    "                     compute_target = cluster,\n",
    "                     entry_script = \"steps/train.py\", \n",
    "                     use_gpu = True,\n",
    "                     framework_version='1.3'\n",
    "                )\n",
    "\n",
    "# Create a pipeline step with the TensorFlow Estimator\n",
    "trainOnGpuStep = EstimatorStep(\n",
    "    name='Train Estimator Step',\n",
    "    estimator=trainEstimator,\n",
    "    inputs=[training_data_location],\n",
    "    outputs=[model_location],\n",
    "    compute_target=cluster,\n",
    "    estimator_entry_script_arguments = estimator_script_params\n",
    ") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registerModelStep = PythonScriptStep(name=\"Register model in Model Management\",\n",
    "                            script_name=\"steps/register.py\",\n",
    "                            compute_target=cluster,\n",
    "                            inputs=[model_location],\n",
    "                            arguments=['--model_name', model_name,\n",
    "                                       '--model_assets_path', model_location\n",
    "                                      ],\n",
    "                            source_directory=script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seer_pipeline = Pipeline(workspace=ws, steps=[preProcessDataStep,trainOnGpuStep,registerModelStep])\n",
    "seer_pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpipeline = seer_pipeline.publish(name=\"Simpsons-PyTorch-Pipeline - Training pipeline (From Notebook)\",)\n",
    "print(\"Pipeline Published ID:\"+mlpipeline.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run = mlpipeline.submit(ws,experiment_name)\n",
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldrun = [r for r in experiment.get_runs() if r.id == 'f8936c45-8697-4017-b8dc-940bef32a215'][0]\n",
    "RunDetails(oldrun).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
